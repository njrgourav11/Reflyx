version: '3.8'

services:
  # Production Qdrant with persistent storage
  qdrant:
    image: qdrant/qdrant:latest
    container_name: ai-assistant-qdrant-prod
    ports:
      - "6333:6333"
    volumes:
      - /var/lib/qdrant:/qdrant/storage
    environment:
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__SERVICE__GRPC_PORT=6334
      - QDRANT__LOG_LEVEL=INFO
    restart: always
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Production Backend with optimizations
  backend:
    build:
      context: ./server
      dockerfile: Dockerfile.prod
    container_name: ai-assistant-backend-prod
    ports:
      - "8000:8000"
    environment:
      - QDRANT_URL=http://qdrant:6333
      - OLLAMA_URL=http://host.docker.internal:11434
      - EMBEDDING_MODEL=all-MiniLM-L6-v2
      - LOG_LEVEL=WARNING
      - PYTHONPATH=/app
      - WORKERS=4
      - MAX_CONCURRENT_REQUESTS=100
    volumes:
      - /var/cache/ai-assistant:/root/.cache/huggingface
    depends_on:
      qdrant:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: always
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Redis for production caching
  redis:
    image: redis:7-alpine
    container_name: ai-assistant-redis-prod
    ports:
      - "6379:6379"
    volumes:
      - /var/lib/redis:/data
    restart: always
    command: redis-server --appendonly yes --maxmemory 1gb --maxmemory-policy allkeys-lru
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Nginx reverse proxy (optional)
  nginx:
    image: nginx:alpine
    container_name: ai-assistant-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - backend
    restart: always
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.25'

networks:
  default:
    name: ai-assistant-prod-network
